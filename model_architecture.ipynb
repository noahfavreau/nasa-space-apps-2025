{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5sSrp5akx29YYMdKd1AIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahfavreau/nasa-space-apps-2025/blob/main/model_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UqSsZp_xdjDY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from catboost import CatBoostClassifier, cv, Pool\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from xgboost import plot_importance, XGBClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pickle\n",
        "\n",
        "import optuna\n",
        "\n",
        "RANDOM_SEED = 67"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_catboost(X_train, X_val, y_train, y_val, Fold):\n",
        "  catboost_model = CatBoostClassifier(\n",
        "                           iterations=200,\n",
        "                           task_type=\"GPU\",\n",
        "                           devices='0',\n",
        "                           depth=6,\n",
        "                           loss_function='MultiClass',\n",
        "                           verbose=0,\n",
        "                           eval_metric='MultiClass',\n",
        "                           random_state=RANDOM_SEED + Fold\n",
        "                          )\n",
        "\n",
        "  catboost_train_pool = Pool(X_train,\n",
        "                            y_train,\n",
        "                             )\n",
        "\n",
        "  catboost_val_pool = Pool(X_val,\n",
        "                            y_val,\n",
        "                             )\n",
        "\n",
        "  catboost_model.fit(catboost_train_pool,\n",
        "                     eval_set=catboost_val_pool,\n",
        "                     early_stopping_rounds=20,\n",
        "                     use_best_model=True)\n",
        "\n",
        "  catboost_val_preds = catboost_model.predict(X_val)\n",
        "\n",
        "  catboost_accuracy = accuracy_score(y_val, catboost_val_preds)\n",
        "  catboost_report = classification_report(y_val, catboost_val_preds)\n",
        "\n",
        "  catboost_fold_accuracies.append(catboost_accuracy)\n",
        "\n",
        "  return catboost_model, catboost_val_preds, catboost_accuracy"
      ],
      "metadata": {
        "id": "CaBGXOupeCap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "def train_lgb(X_train, X_val, y_train, y_val, Fold):\n",
        "  params = {\n",
        "    'objective' : 'multiclass',\n",
        "    'num_class' : 3,\n",
        "    'metric' : \"multi_logloss\",\n",
        "    'verbose' : -1\n",
        "  }\n",
        "\n",
        "  lgb_train_data = lgb.Dataset(X_train, label=y_train)\n",
        "  lgb_val_data = lgb.Dataset(X_val, label=y_val, reference=lgb_train_data)\n",
        "\n",
        "  lgb_model = lgb.train(params,\n",
        "                      lgb_train_data,\n",
        "                      200,\n",
        "                      callbacks=[lgb.early_stopping(stopping_rounds=20)],\n",
        "                      valid_sets=[lgb_val_data]\n",
        "                        )\n",
        "\n",
        "  lgb_val_preds_proba = lgb_model.predict(X_val,\n",
        "                           num_iteration=lgb_model.best_iteration)\n",
        "\n",
        "  lgb_val_preds = np.argmax(lgb_val_preds_proba, axis=1)\n",
        "\n",
        "\n",
        "  lgb_accuracy = accuracy_score(y_val, lgb_val_preds)\n",
        "  lgb_report = classification_report(y_val, lgb_val_preds)\n",
        "\n",
        "  lgb_fold_accuracies.append(lgb_accuracy)\n",
        "\n",
        "  return lgb_model, lgb_val_preds, lgb_accuracy"
      ],
      "metadata": {
        "id": "wgFHm1ENk5G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_xgb(X_train, X_val, y_train, y_val, Fold):\n",
        "  xgb_model = XGBClassifier(num_classes=3,\n",
        "                          objective='multi:softmax',\n",
        "                          eval_metric='mlogloss',\n",
        "                          use_label_encoder=False,\n",
        "                          max_depth=4,\n",
        "                          n_estimators=100,\n",
        "                          random_state=RANDOM_SEED + Fold)\n",
        "\n",
        "  xgb_model.fit(X_train, y_train)\n",
        "\n",
        "  xgb_val_preds = xgb_model.predict(X_val)\n",
        "\n",
        "\n",
        "  xgb_accuracy = accuracy_score(y_val, xgb_val_preds)\n",
        "  xgb_report = classification_report(y_val, xgb_val_preds)\n",
        "\n",
        "  xgb_fold_accuracies.append(xgb_accuracy)\n",
        "\n",
        "  return xgb_model, xgb_val_preds, xgb_accuracy"
      ],
      "metadata": {
        "id": "0nKka_U8nvif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = None\n",
        "y = None\n",
        "\n",
        "catboost_fold_accuracies = []\n",
        "xgb_fold_accuracies = []\n",
        "lgb_fold_accuracies = []\n",
        "\n",
        "catboost_oof_preds = np.zeros(len(X))\n",
        "xgb_oof_preds = np.zeros(len(X))\n",
        "lgb_oof_preds = np.zeros(len(X))\n",
        "\n",
        "catboost_models = []\n",
        "lgb_models = []\n",
        "xgb_models = []\n",
        "\n",
        "n_splits = 10\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "for Fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "  X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  cb_model, cb_preds, cb_acc = train_catboost(X_train, X_val, y_train, y_val, Fold)\n",
        "  catboost_oof_preds[test_index] = cb_preds\n",
        "  catboost_fold_accuracies.append(cb_acc)\n",
        "  catboost_models.append(cb_model)\n",
        "  print(f\"CatBoost Accuracy: {cb_acc:.4f}\")\n",
        "\n",
        "  xgb_model, xgb_preds, xgb_acc = train_xgb(X_train, X_val, y_train, y_val, Fold)\n",
        "  xgb_oof_preds[test_index] = xgb_preds\n",
        "  xgb_fold_accuracies.append(xgb_acc)\n",
        "  xgb_models.append(xgb_model)\n",
        "  print(f\"XGBoost Accuracy: {xgb_acc:.4f}\")\n",
        "\n",
        "  lgb_model, lgb_preds, lgb_acc = train_lgb(X_train, X_val, y_train, y_val, Fold)\n",
        "  lgb_oof_preds[test_index] = lgb_preds\n",
        "  lgb_fold_accuracies.append(lgb_acc)\n",
        "  lgb_models.append(lgb_model)\n",
        "  print(f\"LGBoost Accuracy: {lgb_acc:.4f}\")\n",
        "\n",
        "catboost_mean_accuracy = np.mean(catboost_fold_accuracies)\n",
        "catboost_std_accuracy = np.std(catboost_fold_accuracies)\n",
        "print(f\"CatBoost : {catboost_mean_accuracy:.4f} (+/- {catboost_std_accuracy:.4f})\")\n",
        "\n",
        "lgb_mean_accuracy = np.mean(lgb_fold_accuracies)\n",
        "lgb_std_accuracy = np.std(lgb_fold_accuracies)\n",
        "print(f\"LGBoost : {lgb_mean_accuracy:.4f} (+/- {lgb_std_accuracy:.4f})\")\n",
        "\n",
        "xgb_mean_accuracy = np.mean(xgb_fold_accuracies)\n",
        "xgb_std_accuracy = np.std(xgb_fold_accuracies)\n",
        "print(f\"XGBoost : {xgb_mean_accuracy:.4f} (+/- {xgb_std_accuracy:.4f})\")"
      ],
      "metadata": {
        "id": "VsMKzppbpKTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_catboost(trial):\n",
        "    params = {\n",
        "        \"iterations\": trial.suggest_int(\"iterations\", 100, 500),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
        "        \"task_type\": \"GPU\",\n",
        "        \"devices\": \"0\",\n",
        "        \"loss_function\": \"MultiClass\",\n",
        "        \"random_seed\": RANDOM_SEED\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_idx, valid_idx in cv.split(X, y):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        model = CatBoostClassifier(**params, verbose=0)\n",
        "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=20, verbose=0)\n",
        "        preds = model.predict(X_val)\n",
        "        acc = accuracy_score(y_val, preds)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "study_cat = optuna.create_study(direction=\"maximize\")\n",
        "study_cat.optimize(objective_catboost, n_trials=30)\n",
        "print(\"Best CatBoost params:\", study_cat.best_params)\n"
      ],
      "metadata": {
        "id": "6L98bGoWC1BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_lgb(trial):\n",
        "    params = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"num_class\": 3,\n",
        "        \"metric\": \"multi_logloss\",\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 15),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_idx, valid_idx in cv.split(X, y):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        train_data = lgb.Dataset(X_train, label=y_train)\n",
        "        val_data = lgb.Dataset(X_val, label=y_val)\n",
        "        model = lgb.train(params, train_data, valid_sets=[val_data], early_stopping_rounds=20, verbose_eval=False)\n",
        "\n",
        "        preds = np.argmax(model.predict(X_val), axis=1)\n",
        "        acc = accuracy_score(y_val, preds)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "study_lgb = optuna.create_study(direction=\"maximize\")\n",
        "study_lgb.optimize(objective_lgb, n_trials=30)\n",
        "print(\"Best LightGBM params:\", study_lgb.best_params)\n"
      ],
      "metadata": {
        "id": "loxVLr4yDcfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_xgb(trial):\n",
        "    params = {\n",
        "        \"objective\": \"multi:softmax\",\n",
        "        \"num_class\": 3,\n",
        "        \"eval_metric\": \"mlogloss\",\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
        "        \"random_state\": RANDOM_SEED\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "    accuracies = []\n",
        "\n",
        "    for train_idx, valid_idx in cv.split(X, y):\n",
        "        X_train, X_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        model = XGBClassifier(**params, use_label_encoder=False)\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_val)\n",
        "        acc = accuracy_score(y_val, preds)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "study_xgb = optuna.create_study(direction=\"maximize\")\n",
        "study_xgb.optimize(objective_xgb, n_trials=30)\n",
        "print(\"Best XGBoost params:\", study_xgb.best_params)\n"
      ],
      "metadata": {
        "id": "-s19NrbWDhuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}